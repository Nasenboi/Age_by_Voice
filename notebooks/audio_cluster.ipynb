{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c73c08",
   "metadata": {},
   "source": [
    "# Audio Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aac7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import SpectralClustering, DBSCAN, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"../data/features.csv\"\n",
    "voices_path = \"../data/voices.csv\"\n",
    "output_path = \"../data/voice_cluster.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(feature_path, index_col=\"clip_id\")\n",
    "voices = pd.read_csv(voices_path, index_col=\"clip_id\")\n",
    "features.shape, voices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cfbdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(features),\n",
    "    index=features.index,\n",
    "    columns=features.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc22a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = voices.merge(features_scaled, left_index=True, right_index=True, how='inner')\n",
    "data.loc[data.voice_age_group == 90, \"voice_age_group\"] = 80\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = data[\"voice_age_group\"].value_counts().min()\n",
    "\n",
    "# Sample each group to match the smallest group size\n",
    "data = (\n",
    "    data.groupby(\"voice_age_group\", group_keys=False)\n",
    "    .apply(lambda x: x.sample(100))\n",
    ")\n",
    "\n",
    "# Verify the balance\n",
    "print(f\"minimum count per group: {min_count}\")\n",
    "print(data[\"voice_age_group\"].value_counts())\n",
    "\n",
    "features_scaled = data[features_scaled.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "cluster = kmeans.fit_predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3, random_state=42, perplexity=20)\n",
    "embeddings = tsne.fit_transform(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64951220",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insert(0, \"cluster\", cluster)\n",
    "data['x'] = embeddings[:, 0]\n",
    "data['y'] = embeddings[:, 1]\n",
    "data['z'] = embeddings[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26812a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(output_path, index_label=\"clip_id\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "age_by_voice",
   "language": "python",
   "name": "age_by_voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

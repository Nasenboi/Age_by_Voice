{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c73c08",
   "metadata": {},
   "source": [
    "# Audio Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aac7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "from sklearn.cluster import OPTICS\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_path = \"../data/features.csv\"\n",
    "voices_path = \"../data/voices.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e3c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(feature_path, index_col=\"clip_id\")\n",
    "voices = pd.read_csv(voices_path, index_col=\"clip_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices.voice_gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fdc3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "voices.voice_age_group.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b698c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(features, voices, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58262a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn 90 and 80 to >= 80\n",
    "data.loc[data.voice_age_group == 90, \"voice_age_group\"] = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfddc9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = data['voice_age_group'].value_counts().min()\n",
    "\n",
    "balanced_sample = (data\n",
    "                 .groupby('voice_age_group', group_keys=False)\n",
    "                 .apply(lambda x: x.sample(min_size, random_state=42)))\n",
    "\n",
    "features = balanced_sample[features.columns]\n",
    "voices = balanced_sample[voices.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2107be",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "features_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(features),\n",
    "    index=features.index,\n",
    "    columns=features.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff483ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = UMAP(\n",
    "    n_components=3,\n",
    "    n_neighbors=100,\n",
    "    min_dist=0.1,\n",
    "    metric='euclidean',\n",
    "    verbose=True\n",
    ")\n",
    "embedding = reducer.fit_transform(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = OPTICS(\n",
    "    min_samples=15,           # Decrease from default 20\n",
    "    xi=0.03,                 # More sensitive to small dips (was 0.05)\n",
    "    metric='cosine',          # Keep for audio\n",
    "    cluster_method='dbscan',  # More consistent than 'xi'\n",
    "    eps=0.45,                # Try 0.3-0.6 range\n",
    "    n_jobs=-1\n",
    ").fit_predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90310ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'x': embedding[:,0],\n",
    "    'y': embedding[:,1],\n",
    "    'z': embedding[:,2],\n",
    "    'cluster': clusters,\n",
    "    'clip_id': features_scaled.index  # Explicitly add the index\n",
    "}).set_index('clip_id').join(voices, how='left')\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ad4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='3d-scatter'),\n",
    "    html.Audio(id='audio-player', controls=True)\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('audio-player', 'src'),\n",
    "    [Input('3d-scatter', 'hoverData')]\n",
    ")\n",
    "def play_audio(hoverData):\n",
    "    if hoverData:\n",
    "        filename = hoverData['points'][0]['customdata'][2]\n",
    "        return f\"/audio_files/{filename}\"  # Serve from your backend\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1f3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "age_by_voice",
   "language": "python",
   "name": "age_by_voice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
